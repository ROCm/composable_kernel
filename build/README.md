We tried different ways of partitioning the matrices on two input matrices. Since the first matrix size is M * K and the second matrix size is K * N, the M-dimension blocks is M/M1, the N-dimension blocks is N/N1, the K-dimension blocks is K/(K1*K0). We can modify the M1, K1, N1 to adjust different sizes of blocks. Besides, we also can modify the size of block B which is the definition of the number of threads in one block. We can conduct through these different metrics and do the experiments in the hope of increasing memory access efficiency and CU usage.
we changed M1, N1, K1, K0, B parameters, and conducted about 30 experiments. We processed the data by writing some evaluation metrics, including cache bandwidth, active CUs and some other metrics into a csv file. We also need to put median runtime into the csv file as this is the metric that we are trying to improve.
Suboptimal block and grid sizes can lead to inefficient utilization of GPU resources, resulting in increased execution time and reduced overall performance. After optimizing the block and grid sizes, we observed a reduction in median kernel runtime from 5760 ns to 4480 ns, which is an improvement of over 20%.

